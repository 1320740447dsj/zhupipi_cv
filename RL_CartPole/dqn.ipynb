{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fb1f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "import swanlab\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0597d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_dim,action_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=state_dim,out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,action_dim)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8e5074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self,state_dim,action_dim):\n",
    "        self.q_net = QNetwork(state_dim,action_dim)\n",
    "        self.target_qnet = QNetwork(state_dim,action_dim)\n",
    "        self.target_qnet.load_state_dict(self.q_net.state_dict())\n",
    "        self.best_net =  QNetwork(state_dim,action_dim)\n",
    "        self.optimizer = optim.Adam(params=self.q_net.parameters(),lr=1e-3)\n",
    "        # 双端队列\n",
    "        self.repaly_buffer = deque(maxlen=10000) \n",
    "        self.batch_size = 64\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 0.1\n",
    "        self.updata_target_freq = 100\n",
    "        self.step_count = 0\n",
    "        self.best_reward = 0\n",
    "        self.best_avg_reward = 0\n",
    "        self.eval_episodes = 5\n",
    "    def choose_action(self,state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(0, 2)  # CartPole有2个动作（左/右）\n",
    "        else:\n",
    "            state_tensor = torch.FloatTensor(state)\n",
    "            outputs = self.q_net(state_tensor)\n",
    "            action = outputs.cpu().detach().numpy().argmax()\n",
    "            return action\n",
    "        \n",
    "    def store_experience(self,state,action,reward,next_state,done):\n",
    "        self.repaly_buffer.append((state,action,reward,next_state,done))\n",
    "    \n",
    "    def train(self):\n",
    "        if len(self.repaly_buffer) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        batch = random.sample(population=self.repaly_buffer,k=self.batch_size)\n",
    "        state,action,reward,next_state,done = zip(*batch)\n",
    "\n",
    "        state = torch.FloatTensor(np.array(state))\n",
    "        action = torch.LongTensor(action)\n",
    "        reward = torch.FloatTensor(reward)\n",
    "        next_state = torch.FloatTensor(np.array(next_state))\n",
    "        done = torch.FloatTensor(done)\n",
    "\n",
    "        current_q = self.q_net(state).gather(1,action.unsqueeze(1)).squeeze()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_q = self.target_qnet(next_state).max(1)[0]\n",
    "            target_q = reward + self.gamma * next_q  *(1-done)\n",
    "        loss = nn.MSELoss()(current_q,target_q)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        self.step_count +=1\n",
    "        if self.step_count % self.updata_target_freq == 0:\n",
    "            self.target_qnet.load_state_dict({\n",
    "                k: v.clone() for k, v in self.q_net.state_dict().items()\n",
    "            })\n",
    "    \n",
    "    def save_model(self,path):\n",
    "        if not os.path.exists(\"./output\"):\n",
    "            os.makedirs(\"./output\")\n",
    "        torch.save(self.q_net.state_dict(),f=path)\n",
    "        print(\"model save success\")\n",
    "\n",
    "    def evaluate(self,env):\n",
    "        original_epsilon = self.epsilon\n",
    "        self.epsilon = 0\n",
    "        totoal_rewards = []\n",
    "\n",
    "        for _ in range(self.eval_episodes):\n",
    "            state = env.reset()[0]\n",
    "            episode_reward = 0\n",
    "            while True:\n",
    "                action = self.choose_action(state)\n",
    "                next_state,reward,done,_,_ = env.step(action)\n",
    "                episode_reward +=reward\n",
    "                state = next_state\n",
    "                if done or episode_reward > 2e4:\n",
    "                    break\n",
    "            totoal_rewards.append(episode_reward)\n",
    "\n",
    "        self.epsilon = original_epsilon\n",
    "        return np.mean(totoal_rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebdfde41",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "agent = DQNAgent(state_dim, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87d3068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model save success\n",
      "New best model saved with average reward: 9.4\n",
      "Episode: 0, Train Reward: 50.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 1, Train Reward: 21.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 2, Train Reward: 37.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 3, Train Reward: 28.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 4, Train Reward: 24.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 5, Train Reward: 22.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 6, Train Reward: 13.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 7, Train Reward: 11.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 8, Train Reward: 26.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 9, Train Reward: 14.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 10, Train Reward: 14.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 11, Train Reward: 20.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 12, Train Reward: 21.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 13, Train Reward: 20.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 14, Train Reward: 18.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 15, Train Reward: 16.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 16, Train Reward: 18.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 17, Train Reward: 19.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 18, Train Reward: 15.0, Best Eval Avg Reward: 9.4\n",
      "Episode: 19, Train Reward: 17.0, Best Eval Avg Reward: 9.4\n",
      "model save success\n",
      "New best model saved with average reward: 28.0\n",
      "Episode: 20, Train Reward: 26.0, Best Eval Avg Reward: 28.0\n",
      "Episode: 21, Train Reward: 13.0, Best Eval Avg Reward: 28.0\n",
      "Episode: 22, Train Reward: 23.0, Best Eval Avg Reward: 28.0\n",
      "Episode: 23, Train Reward: 27.0, Best Eval Avg Reward: 28.0\n",
      "Episode: 24, Train Reward: 18.0, Best Eval Avg Reward: 28.0\n",
      "Episode: 25, Train Reward: 17.0, Best Eval Avg Reward: 28.0\n",
      "Episode: 26, Train Reward: 11.0, Best Eval Avg Reward: 28.0\n",
      "Episode: 27, Train Reward: 49.0, Best Eval Avg Reward: 28.0\n",
      "Episode: 28, Train Reward: 12.0, Best Eval Avg Reward: 28.0\n",
      "Episode: 29, Train Reward: 10.0, Best Eval Avg Reward: 28.0\n",
      "model save success\n",
      "New best model saved with average reward: 113.6\n",
      "Episode: 30, Train Reward: 10.0, Best Eval Avg Reward: 113.6\n",
      "Episode: 31, Train Reward: 29.0, Best Eval Avg Reward: 113.6\n",
      "Episode: 32, Train Reward: 20.0, Best Eval Avg Reward: 113.6\n",
      "Episode: 33, Train Reward: 17.0, Best Eval Avg Reward: 113.6\n",
      "Episode: 34, Train Reward: 117.0, Best Eval Avg Reward: 113.6\n",
      "Episode: 35, Train Reward: 13.0, Best Eval Avg Reward: 113.6\n",
      "Episode: 36, Train Reward: 41.0, Best Eval Avg Reward: 113.6\n",
      "Episode: 37, Train Reward: 26.0, Best Eval Avg Reward: 113.6\n",
      "Episode: 38, Train Reward: 34.0, Best Eval Avg Reward: 113.6\n",
      "Episode: 39, Train Reward: 16.0, Best Eval Avg Reward: 113.6\n",
      "model save success\n",
      "New best model saved with average reward: 120.0\n",
      "Episode: 40, Train Reward: 41.0, Best Eval Avg Reward: 120.0\n",
      "Episode: 41, Train Reward: 23.0, Best Eval Avg Reward: 120.0\n",
      "Episode: 42, Train Reward: 12.0, Best Eval Avg Reward: 120.0\n",
      "Episode: 43, Train Reward: 64.0, Best Eval Avg Reward: 120.0\n",
      "Episode: 44, Train Reward: 14.0, Best Eval Avg Reward: 120.0\n",
      "Episode: 45, Train Reward: 24.0, Best Eval Avg Reward: 120.0\n",
      "Episode: 46, Train Reward: 30.0, Best Eval Avg Reward: 120.0\n",
      "Episode: 47, Train Reward: 118.0, Best Eval Avg Reward: 120.0\n",
      "Episode: 48, Train Reward: 26.0, Best Eval Avg Reward: 120.0\n",
      "Episode: 49, Train Reward: 93.0, Best Eval Avg Reward: 120.0\n",
      "model save success\n",
      "New best model saved with average reward: 252.4\n",
      "Episode: 50, Train Reward: 76.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 51, Train Reward: 16.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 52, Train Reward: 43.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 53, Train Reward: 11.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 54, Train Reward: 37.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 55, Train Reward: 11.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 56, Train Reward: 18.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 57, Train Reward: 14.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 58, Train Reward: 26.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 59, Train Reward: 105.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 60, Train Reward: 17.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 61, Train Reward: 48.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 62, Train Reward: 42.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 63, Train Reward: 10.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 64, Train Reward: 19.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 65, Train Reward: 25.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 66, Train Reward: 42.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 67, Train Reward: 40.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 68, Train Reward: 18.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 69, Train Reward: 16.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 70, Train Reward: 13.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 71, Train Reward: 56.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 72, Train Reward: 27.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 73, Train Reward: 61.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 74, Train Reward: 15.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 75, Train Reward: 93.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 76, Train Reward: 21.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 77, Train Reward: 23.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 78, Train Reward: 123.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 79, Train Reward: 20.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 80, Train Reward: 39.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 81, Train Reward: 89.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 82, Train Reward: 57.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 83, Train Reward: 28.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 84, Train Reward: 99.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 85, Train Reward: 174.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 86, Train Reward: 13.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 87, Train Reward: 22.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 88, Train Reward: 24.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 89, Train Reward: 40.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 90, Train Reward: 89.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 91, Train Reward: 16.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 92, Train Reward: 19.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 93, Train Reward: 118.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 94, Train Reward: 19.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 95, Train Reward: 94.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 96, Train Reward: 18.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 97, Train Reward: 37.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 98, Train Reward: 77.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 99, Train Reward: 71.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 100, Train Reward: 17.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 101, Train Reward: 53.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 102, Train Reward: 30.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 103, Train Reward: 12.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 104, Train Reward: 99.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 105, Train Reward: 118.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 106, Train Reward: 45.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 107, Train Reward: 42.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 108, Train Reward: 25.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 109, Train Reward: 40.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 110, Train Reward: 54.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 111, Train Reward: 22.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 112, Train Reward: 75.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 113, Train Reward: 51.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 114, Train Reward: 18.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 115, Train Reward: 168.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 116, Train Reward: 34.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 117, Train Reward: 196.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 118, Train Reward: 70.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 119, Train Reward: 88.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 120, Train Reward: 113.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 121, Train Reward: 78.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 122, Train Reward: 117.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 123, Train Reward: 19.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 124, Train Reward: 263.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 125, Train Reward: 65.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 126, Train Reward: 43.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 127, Train Reward: 16.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 128, Train Reward: 35.0, Best Eval Avg Reward: 252.4\n",
      "Episode: 129, Train Reward: 82.0, Best Eval Avg Reward: 252.4\n",
      "model save success\n",
      "New best model saved with average reward: 254.6\n",
      "Episode: 130, Train Reward: 40.0, Best Eval Avg Reward: 254.6\n",
      "Episode: 131, Train Reward: 23.0, Best Eval Avg Reward: 254.6\n",
      "Episode: 132, Train Reward: 183.0, Best Eval Avg Reward: 254.6\n",
      "Episode: 133, Train Reward: 65.0, Best Eval Avg Reward: 254.6\n",
      "Episode: 134, Train Reward: 65.0, Best Eval Avg Reward: 254.6\n",
      "Episode: 135, Train Reward: 206.0, Best Eval Avg Reward: 254.6\n",
      "Episode: 136, Train Reward: 20.0, Best Eval Avg Reward: 254.6\n",
      "Episode: 137, Train Reward: 71.0, Best Eval Avg Reward: 254.6\n",
      "Episode: 138, Train Reward: 144.0, Best Eval Avg Reward: 254.6\n",
      "Episode: 139, Train Reward: 192.0, Best Eval Avg Reward: 254.6\n",
      "model save success\n",
      "New best model saved with average reward: 264.4\n",
      "Episode: 140, Train Reward: 158.0, Best Eval Avg Reward: 264.4\n",
      "Episode: 141, Train Reward: 60.0, Best Eval Avg Reward: 264.4\n",
      "Episode: 142, Train Reward: 71.0, Best Eval Avg Reward: 264.4\n",
      "Episode: 143, Train Reward: 46.0, Best Eval Avg Reward: 264.4\n",
      "Episode: 144, Train Reward: 205.0, Best Eval Avg Reward: 264.4\n",
      "Episode: 145, Train Reward: 33.0, Best Eval Avg Reward: 264.4\n",
      "Episode: 146, Train Reward: 103.0, Best Eval Avg Reward: 264.4\n",
      "Episode: 147, Train Reward: 46.0, Best Eval Avg Reward: 264.4\n",
      "Episode: 148, Train Reward: 39.0, Best Eval Avg Reward: 264.4\n",
      "Episode: 149, Train Reward: 209.0, Best Eval Avg Reward: 264.4\n",
      "model save success\n",
      "New best model saved with average reward: 16211.4\n",
      "Episode: 150, Train Reward: 260.0, Best Eval Avg Reward: 16211.4\n",
      "Episode: 151, Train Reward: 155.0, Best Eval Avg Reward: 16211.4\n",
      "Episode: 152, Train Reward: 39.0, Best Eval Avg Reward: 16211.4\n",
      "Episode: 153, Train Reward: 90.0, Best Eval Avg Reward: 16211.4\n",
      "Episode: 154, Train Reward: 140.0, Best Eval Avg Reward: 16211.4\n",
      "Episode: 155, Train Reward: 90.0, Best Eval Avg Reward: 16211.4\n",
      "Episode: 156, Train Reward: 119.0, Best Eval Avg Reward: 16211.4\n",
      "Episode: 157, Train Reward: 76.0, Best Eval Avg Reward: 16211.4\n",
      "Episode: 158, Train Reward: 31.0, Best Eval Avg Reward: 16211.4\n",
      "Episode: 159, Train Reward: 68.0, Best Eval Avg Reward: 16211.4\n",
      "model save success\n",
      "New best model saved with average reward: 20001.0\n",
      "Episode: 160, Train Reward: 107.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 161, Train Reward: 93.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 162, Train Reward: 220.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 163, Train Reward: 88.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 164, Train Reward: 183.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 165, Train Reward: 23.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 166, Train Reward: 69.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 167, Train Reward: 38.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 168, Train Reward: 116.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 169, Train Reward: 93.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 170, Train Reward: 60.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 171, Train Reward: 44.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 172, Train Reward: 129.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 173, Train Reward: 36.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 174, Train Reward: 88.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 175, Train Reward: 90.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 176, Train Reward: 43.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 177, Train Reward: 84.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 178, Train Reward: 35.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 179, Train Reward: 49.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 180, Train Reward: 353.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 181, Train Reward: 108.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 182, Train Reward: 12.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 183, Train Reward: 46.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 184, Train Reward: 123.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 185, Train Reward: 27.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 186, Train Reward: 38.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 187, Train Reward: 123.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 188, Train Reward: 26.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 189, Train Reward: 146.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 190, Train Reward: 167.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 191, Train Reward: 12.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 192, Train Reward: 46.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 193, Train Reward: 12.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 194, Train Reward: 36.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 195, Train Reward: 238.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 196, Train Reward: 34.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 197, Train Reward: 71.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 198, Train Reward: 55.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 199, Train Reward: 39.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 200, Train Reward: 61.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 201, Train Reward: 33.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 202, Train Reward: 14.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 203, Train Reward: 41.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 204, Train Reward: 591.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 205, Train Reward: 124.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 206, Train Reward: 107.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 207, Train Reward: 78.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 208, Train Reward: 78.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 209, Train Reward: 328.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 210, Train Reward: 96.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 211, Train Reward: 358.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 212, Train Reward: 269.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 213, Train Reward: 168.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 214, Train Reward: 189.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 215, Train Reward: 135.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 216, Train Reward: 137.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 217, Train Reward: 46.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 218, Train Reward: 120.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 219, Train Reward: 30.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 220, Train Reward: 381.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 221, Train Reward: 53.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 222, Train Reward: 190.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 223, Train Reward: 144.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 224, Train Reward: 10.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 225, Train Reward: 112.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 226, Train Reward: 195.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 227, Train Reward: 143.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 228, Train Reward: 24.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 229, Train Reward: 16.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 230, Train Reward: 14.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 231, Train Reward: 453.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 232, Train Reward: 281.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 233, Train Reward: 168.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 234, Train Reward: 30.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 235, Train Reward: 145.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 236, Train Reward: 137.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 237, Train Reward: 16.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 238, Train Reward: 122.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 239, Train Reward: 23.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 240, Train Reward: 118.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 241, Train Reward: 131.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 242, Train Reward: 382.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 243, Train Reward: 18.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 244, Train Reward: 355.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 245, Train Reward: 171.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 246, Train Reward: 146.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 247, Train Reward: 380.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 248, Train Reward: 36.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 249, Train Reward: 118.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 250, Train Reward: 138.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 251, Train Reward: 129.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 252, Train Reward: 49.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 253, Train Reward: 131.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 254, Train Reward: 133.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 255, Train Reward: 136.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 256, Train Reward: 133.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 257, Train Reward: 30.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 258, Train Reward: 127.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 259, Train Reward: 141.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 260, Train Reward: 127.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 261, Train Reward: 16.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 262, Train Reward: 48.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 263, Train Reward: 5916.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 264, Train Reward: 170.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 265, Train Reward: 138.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 266, Train Reward: 136.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 267, Train Reward: 1269.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 268, Train Reward: 906.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 269, Train Reward: 178.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 270, Train Reward: 1062.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 271, Train Reward: 324.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 272, Train Reward: 66.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 273, Train Reward: 1524.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 274, Train Reward: 241.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 275, Train Reward: 1391.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 276, Train Reward: 236.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 277, Train Reward: 1040.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 278, Train Reward: 1218.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 279, Train Reward: 223.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 280, Train Reward: 318.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 281, Train Reward: 321.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 282, Train Reward: 325.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 283, Train Reward: 267.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 284, Train Reward: 323.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 285, Train Reward: 276.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 286, Train Reward: 219.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 287, Train Reward: 253.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 288, Train Reward: 188.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 289, Train Reward: 209.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 290, Train Reward: 355.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 291, Train Reward: 392.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 292, Train Reward: 815.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 293, Train Reward: 319.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 294, Train Reward: 183.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 295, Train Reward: 69.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 296, Train Reward: 343.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 297, Train Reward: 112.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 298, Train Reward: 203.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 299, Train Reward: 642.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 300, Train Reward: 172.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 301, Train Reward: 164.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 302, Train Reward: 41.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 303, Train Reward: 255.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 304, Train Reward: 171.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 305, Train Reward: 198.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 306, Train Reward: 221.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 307, Train Reward: 84.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 308, Train Reward: 100.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 309, Train Reward: 94.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 310, Train Reward: 136.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 311, Train Reward: 126.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 312, Train Reward: 83.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 313, Train Reward: 12.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 314, Train Reward: 142.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 315, Train Reward: 133.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 316, Train Reward: 136.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 317, Train Reward: 140.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 318, Train Reward: 124.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 319, Train Reward: 109.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 320, Train Reward: 146.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 321, Train Reward: 139.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 322, Train Reward: 141.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 323, Train Reward: 125.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 324, Train Reward: 151.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 325, Train Reward: 181.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 326, Train Reward: 121.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 327, Train Reward: 155.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 328, Train Reward: 120.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 329, Train Reward: 140.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 330, Train Reward: 118.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 331, Train Reward: 122.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 332, Train Reward: 116.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 333, Train Reward: 120.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 334, Train Reward: 108.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 335, Train Reward: 114.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 336, Train Reward: 124.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 337, Train Reward: 118.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 338, Train Reward: 115.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 339, Train Reward: 14.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 340, Train Reward: 110.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 341, Train Reward: 112.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 342, Train Reward: 118.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 343, Train Reward: 125.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 344, Train Reward: 120.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 345, Train Reward: 80.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 346, Train Reward: 116.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 347, Train Reward: 68.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 348, Train Reward: 127.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 349, Train Reward: 14.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 350, Train Reward: 125.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 351, Train Reward: 121.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 352, Train Reward: 59.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 353, Train Reward: 86.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 354, Train Reward: 126.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 355, Train Reward: 80.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 356, Train Reward: 130.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 357, Train Reward: 119.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 358, Train Reward: 99.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 359, Train Reward: 70.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 360, Train Reward: 69.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 361, Train Reward: 141.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 362, Train Reward: 99.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 363, Train Reward: 142.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 364, Train Reward: 123.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 365, Train Reward: 133.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 366, Train Reward: 102.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 367, Train Reward: 146.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 368, Train Reward: 158.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 369, Train Reward: 104.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 370, Train Reward: 174.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 371, Train Reward: 189.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 372, Train Reward: 173.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 373, Train Reward: 189.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 374, Train Reward: 189.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 375, Train Reward: 249.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 376, Train Reward: 3839.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 377, Train Reward: 775.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 378, Train Reward: 1269.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 379, Train Reward: 633.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 380, Train Reward: 6030.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 381, Train Reward: 135.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 382, Train Reward: 472.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 383, Train Reward: 117.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 384, Train Reward: 277.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 385, Train Reward: 129.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 386, Train Reward: 118.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 387, Train Reward: 138.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 388, Train Reward: 125.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 389, Train Reward: 125.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 390, Train Reward: 134.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 391, Train Reward: 122.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 392, Train Reward: 126.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 393, Train Reward: 126.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 394, Train Reward: 134.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 395, Train Reward: 131.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 396, Train Reward: 135.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 397, Train Reward: 129.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 398, Train Reward: 137.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 399, Train Reward: 140.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 400, Train Reward: 134.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 401, Train Reward: 136.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 402, Train Reward: 132.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 403, Train Reward: 144.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 404, Train Reward: 102.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 405, Train Reward: 405.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 406, Train Reward: 173.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 407, Train Reward: 644.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 408, Train Reward: 358.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 409, Train Reward: 119.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 410, Train Reward: 345.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 411, Train Reward: 320.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 412, Train Reward: 54.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 413, Train Reward: 491.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 414, Train Reward: 153.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 415, Train Reward: 63.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 416, Train Reward: 483.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 417, Train Reward: 274.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 418, Train Reward: 135.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 419, Train Reward: 299.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 420, Train Reward: 648.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 421, Train Reward: 2425.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 422, Train Reward: 180.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 423, Train Reward: 1802.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 424, Train Reward: 105.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 425, Train Reward: 360.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 426, Train Reward: 312.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 427, Train Reward: 7407.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 428, Train Reward: 49.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 429, Train Reward: 15.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 430, Train Reward: 1044.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 431, Train Reward: 97.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 432, Train Reward: 33.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 433, Train Reward: 113.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 434, Train Reward: 133.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 435, Train Reward: 442.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 436, Train Reward: 3462.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 437, Train Reward: 128.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 438, Train Reward: 7866.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 439, Train Reward: 2958.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 440, Train Reward: 260.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 441, Train Reward: 238.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 442, Train Reward: 352.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 443, Train Reward: 204.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 444, Train Reward: 134.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 445, Train Reward: 169.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 446, Train Reward: 160.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 447, Train Reward: 214.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 448, Train Reward: 235.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 449, Train Reward: 132.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 450, Train Reward: 133.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 451, Train Reward: 126.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 452, Train Reward: 127.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 453, Train Reward: 118.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 454, Train Reward: 124.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 455, Train Reward: 121.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 456, Train Reward: 128.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 457, Train Reward: 134.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 458, Train Reward: 131.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 459, Train Reward: 128.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 460, Train Reward: 133.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 461, Train Reward: 133.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 462, Train Reward: 133.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 463, Train Reward: 128.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 464, Train Reward: 137.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 465, Train Reward: 144.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 466, Train Reward: 142.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 467, Train Reward: 144.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 468, Train Reward: 141.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 469, Train Reward: 146.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 470, Train Reward: 152.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 471, Train Reward: 166.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 472, Train Reward: 163.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 473, Train Reward: 146.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 474, Train Reward: 185.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 475, Train Reward: 165.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 476, Train Reward: 164.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 477, Train Reward: 157.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 478, Train Reward: 156.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 479, Train Reward: 165.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 480, Train Reward: 165.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 481, Train Reward: 152.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 482, Train Reward: 15.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 483, Train Reward: 162.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 484, Train Reward: 176.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 485, Train Reward: 196.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 486, Train Reward: 222.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 487, Train Reward: 12182.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 488, Train Reward: 33.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 489, Train Reward: 44.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 490, Train Reward: 41.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 491, Train Reward: 42.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 492, Train Reward: 67.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 493, Train Reward: 94.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 494, Train Reward: 100.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 495, Train Reward: 93.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 496, Train Reward: 25.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 497, Train Reward: 94.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 498, Train Reward: 97.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 499, Train Reward: 105.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 500, Train Reward: 102.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 501, Train Reward: 124.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 502, Train Reward: 134.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 503, Train Reward: 160.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 504, Train Reward: 218.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 505, Train Reward: 222.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 506, Train Reward: 224.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 507, Train Reward: 258.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 508, Train Reward: 279.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 509, Train Reward: 247.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 510, Train Reward: 250.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 511, Train Reward: 218.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 512, Train Reward: 210.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 513, Train Reward: 223.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 514, Train Reward: 232.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 515, Train Reward: 253.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 516, Train Reward: 213.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 517, Train Reward: 219.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 518, Train Reward: 271.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 519, Train Reward: 274.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 520, Train Reward: 308.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 521, Train Reward: 562.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 522, Train Reward: 5049.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 523, Train Reward: 257.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 524, Train Reward: 199.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 525, Train Reward: 223.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 526, Train Reward: 198.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 527, Train Reward: 185.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 528, Train Reward: 175.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 529, Train Reward: 215.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 530, Train Reward: 196.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 531, Train Reward: 217.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 532, Train Reward: 511.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 533, Train Reward: 1783.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 534, Train Reward: 83.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 535, Train Reward: 413.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 536, Train Reward: 178.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 537, Train Reward: 592.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 538, Train Reward: 189.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 539, Train Reward: 2275.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 540, Train Reward: 4137.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 541, Train Reward: 165.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 542, Train Reward: 682.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 543, Train Reward: 877.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 544, Train Reward: 1755.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 545, Train Reward: 2049.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 546, Train Reward: 125.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 547, Train Reward: 136.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 548, Train Reward: 1087.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 549, Train Reward: 316.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 550, Train Reward: 163.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 551, Train Reward: 215.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 552, Train Reward: 120.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 553, Train Reward: 148.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 554, Train Reward: 138.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 555, Train Reward: 407.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 556, Train Reward: 1284.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 557, Train Reward: 730.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 558, Train Reward: 4603.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 559, Train Reward: 1245.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 560, Train Reward: 388.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 561, Train Reward: 234.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 562, Train Reward: 146.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 563, Train Reward: 24.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 564, Train Reward: 153.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 565, Train Reward: 135.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 566, Train Reward: 138.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 567, Train Reward: 117.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 568, Train Reward: 144.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 569, Train Reward: 126.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 570, Train Reward: 129.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 571, Train Reward: 161.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 572, Train Reward: 136.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 573, Train Reward: 130.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 574, Train Reward: 133.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 575, Train Reward: 130.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 576, Train Reward: 141.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 577, Train Reward: 219.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 578, Train Reward: 139.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 579, Train Reward: 178.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 580, Train Reward: 2893.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 581, Train Reward: 94.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 582, Train Reward: 100.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 583, Train Reward: 98.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 584, Train Reward: 94.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 585, Train Reward: 97.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 586, Train Reward: 105.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 587, Train Reward: 101.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 588, Train Reward: 98.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 589, Train Reward: 101.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 590, Train Reward: 102.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 591, Train Reward: 108.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 592, Train Reward: 112.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 593, Train Reward: 115.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 594, Train Reward: 111.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 595, Train Reward: 110.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 596, Train Reward: 112.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 597, Train Reward: 114.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 598, Train Reward: 122.0, Best Eval Avg Reward: 20001.0\n",
      "Episode: 599, Train Reward: 118.0, Best Eval Avg Reward: 20001.0\n"
     ]
    }
   ],
   "source": [
    "agent.epsilon = 1\n",
    "for episode in range(600):\n",
    "    state = env.reset()[0]\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    while True:\n",
    "        action = agent.choose_action(state)\n",
    "        next_state , reward, done,_,_, = env.step(action=action)\n",
    "        agent.store_experience(state,action,reward,next_state,done)\n",
    "        agent.train()\n",
    "        total_reward +=reward\n",
    "        state = next_state\n",
    "        if done or total_reward > 2e4:\n",
    "            break\n",
    "    agent.epsilon = max(0.01,agent.epsilon*0.995)\n",
    "\n",
    "    if episode % 10 ==0:\n",
    "        eval_env = gym.make('CartPole-v1')\n",
    "        avg_reward = agent.evaluate(eval_env)\n",
    "        eval_env.close()\n",
    "        if avg_reward > agent.best_avg_reward:\n",
    "            agent.best_avg_reward = avg_reward\n",
    "            agent.best_net.load_state_dict({k: v.clone() for k, v in agent.q_net.state_dict().items()})\n",
    "            agent.save_model(path=f\"./output/best_model.pth\")\n",
    "            print(f\"New best model saved with average reward: {avg_reward}\")\n",
    "\n",
    "    print(f\"Episode: {episode}, Train Reward: {total_reward}, Best Eval Avg Reward: {agent.best_avg_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eda39ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.epsilon = 0\n",
    "test_env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "test_env = RecordVideo(test_env, \"./dqn_videos\", episode_trigger=lambda x: True)\n",
    "agent.q_net.load_state_dict(state_dict=agent.best_net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7558ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test episode 0, rewards 1500.0\n",
      "Test episode 1, rewards 1500.0\n",
      "Test episode 2, rewards 1500.0\n",
      "Test episode 3, rewards 1500.0\n",
      "Test episode 4, rewards 1500.0\n"
     ]
    }
   ],
   "source": [
    "for episodes in range(5):\n",
    "    state = test_env.reset()[0]\n",
    "    total_reward = 0\n",
    "    step = 0\n",
    "    while True:\n",
    "        action = agent.choose_action(state)\n",
    "        next_state,reward,done,_,_ = test_env.step(action)\n",
    "        total_reward+=reward\n",
    "        state = next_state\n",
    "        step +=1\n",
    "        if done or step >= 1500:\n",
    "            break\n",
    "    print(f\"Test episode {episodes}, rewards {total_reward}\")\n",
    "\n",
    "test_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf49792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047775be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce98b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
